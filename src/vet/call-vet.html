<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Waiting for Vet</title>
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
  <link rel="stylesheet" href="vet.css">
  <script src="https://download.agora.io/sdk/release/AgoraRTC_N.js"></script>
</head>
<body>
  <div class="vet-container">
    <!-- Header -->
    <header class="vet-header">
      <div class="vet-logo">
        <i class="fas fa-paw"></i>
        <span>Paws+</span>
      </div>
      <p class="vet-subtitle">Connecting with a Veterinarian</p>
    </header>

    <!-- Main Content -->
    <main class="vet-card" style="padding: 25px;">
      <div class="vet-conversation">
        <!-- Status Display -->
        <div class="vet-conversation-header">
          <div class="vet-pet-info">
            <div class="vet-pet-avatar" id="pet-avatar">üêï</div>
            <div class="vet-pet-details">
              <h3 id="pet-name">Your Pet</h3>
              <p id="pet-details">Loading...</p>
            </div>
          </div>
          <div class="vet-status vet-status-connecting" id="call-status">
            <i class="fas fa-circle-notch fa-spin"></i>
            <span id="status-text">Requesting Call...</span>
          </div>
        </div>

        <!-- Waiting/Call UI -->
        <div class="vet-audio-container">
          <div class="vet-audio-indicator" id="audio-indicator">
            <i class="fas fa-user-md" id="call-icon"></i>
          </div>
          <p class="vet-audio-status" id="audio-status">Requesting a veterinarian...</p>
          <p class="vet-audio-hint" id="audio-hint">A vet will be with you shortly. Please ensure your microphone is ready.</p>
          <p id="call-duration" style="font-size: 2rem; font-weight: bold; color: var(--vet-primary); margin-top: 20px; display: none;">00:00</p>
        </div>

        <!-- Queue Position -->
        <div id="queue-info" style="text-align: center; margin: 20px 0; display: none;">
          <p style="font-size: 1.1rem; color: var(--text-secondary);">Estimated wait time:</p>
          <p style="font-size: 1.5rem; font-weight: bold; color: var(--vet-primary);" id="wait-time">~2 minutes</p>
        </div>

        <!-- Video Container -->
        <div class="vet-video-container" style="margin-top: 20px; display: none;" id="video-section">
          <!-- Remote Video -->
          <div id="remote-playerlist" class="vet-remote-video">
            <div class="vet-video-placeholder" id="video-placeholder">
              <div class="vet-audio-indicator inactive">
                <i class="fas fa-user-md"></i>
              </div>
              <p class="vet-audio-status">Waiting for vet video...</p>
              <p class="vet-audio-hint">You'll see the vet once their camera starts.</p>
            </div>
          </div>

          <!-- Local Video -->
          <div id="local-player" class="vet-local-video">
            <div class="vet-local-player-name">You</div>
          </div>
        </div>

        <!-- Controls -->
        <div class="vet-controls" id="controls" style="display: none;">
          <button class="vet-control-btn vet-control-btn-mute" id="mute-btn" title="Mute/Unmute" disabled>
            <i class="fas fa-microphone"></i>
          </button>
          <button class="vet-control-btn vet-control-btn-video" id="video-btn" title="Camera On/Off" disabled>
            <i class="fas fa-video"></i>
          </button>
          <button class="vet-control-btn vet-control-btn-end" id="end-btn" title="Cancel Call">
            <i class="fas fa-phone-slash"></i>
          </button>
        </div>

        <!-- Cancel Button (shown while waiting) -->
        <div id="waiting-controls" style="text-align: center; margin-top: 30px;">
          <button class="vet-btn vet-btn-secondary" id="cancel-btn">
            <i class="fas fa-times"></i> Cancel Request
          </button>
        </div>
      </div>
    </main>

    <!-- Triage Summary -->
    <div class="vet-card" id="summary-card" style="padding: 20px; margin-top: 20px;">
      <h4 style="color: var(--vet-primary); margin-bottom: 15px;">
        <i class="fas fa-clipboard-list"></i> Your Triage Summary
      </h4>
      <div id="summary-content">
        <p><strong>Urgency:</strong> <span id="urgency-level">Medium</span></p>
        <p style="margin-top: 10px;"><strong>AI Recommendation:</strong></p>
        <p id="recommendation-text" style="color: var(--text-secondary); margin-top: 5px;">Loading...</p>
      </div>
    </div>

    <!-- Footer Note -->
    <footer class="vet-footer-note">
      <i class="fas fa-phone"></i>
      A veterinarian will join this call to discuss your pet's condition.
    </footer>
  </div>

  <!-- Toast Notification -->
  <div class="vet-toast" id="toast"></div>

  <script>
    /**
     * ===========================================
     * HARDCODED VALUES FOR DEMO - EASY TO REPLACE
     * ===========================================
     */
    
    // ===== HARDCODED VALUES (Replace with server config later) =====
    const FIXED_CALL_CHANNEL = "vet-human-call";
    const USER_UID = 20000;  // User's ID for calls
    // ===============================================================

    // Agora state
    let client = null;
    let localAudioTrack = null;
    let localVideoTrack = null;
    let isMuted = false;
    let isVideoEnabled = true;
    let callStartTime = null;
    let durationInterval = null;
    let statusPollInterval = null;
    let isInCall = false;
    let bookingId = null;
    let booking = null;

    // Call recording state
    let mediaRecorder = null;
    let audioRecordings = [];
    let recordingStartTime = null;
    let audioContext = null;
    let combinedStream = null;

    // Config
    let appId = null;
    let token = null;
    let channelName = FIXED_CALL_CHANNEL;  // Set channel name immediately to fix null token issue

    // Pet info
    let petInfo = null;
    let triageSummary = null;

    // DOM Elements
    const petAvatar = document.getElementById('pet-avatar');
    const petName = document.getElementById('pet-name');
    const petDetails = document.getElementById('pet-details');
    const callStatus = document.getElementById('call-status');
    const statusText = document.getElementById('status-text');
    const audioIndicator = document.getElementById('audio-indicator');
    const callIcon = document.getElementById('call-icon');
    const audioStatus = document.getElementById('audio-status');
    const audioHint = document.getElementById('audio-hint');
    const callDuration = document.getElementById('call-duration');
    const queueInfo = document.getElementById('queue-info');
    const waitTime = document.getElementById('wait-time');
    const controls = document.getElementById('controls');
    const videoSection = document.getElementById('video-section');
    const remotePlayerList = document.getElementById('remote-playerlist');
    const videoPlaceholder = document.getElementById('video-placeholder');
    const waitingControls = document.getElementById('waiting-controls');
    const muteBtn = document.getElementById('mute-btn');
    const videoBtn = document.getElementById('video-btn');
    const endBtn = document.getElementById('end-btn');
    const cancelBtn = document.getElementById('cancel-btn');
    const urgencyLevel = document.getElementById('urgency-level');
    const recommendationText = document.getElementById('recommendation-text');
    const toast = document.getElementById('toast');

    // Show toast
    function showToast(message, duration = 3000) {
      toast.textContent = message;
      toast.classList.add('show');
      setTimeout(() => toast.classList.remove('show'), duration);
    }

    // Start call recording
    async function startCallRecording() {
      try {
        console.log('Starting call recording...');
        
        // Create audio context for mixing streams
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        const destination = audioContext.createMediaStreamDestination();
        
        // Get user's microphone stream
        const userStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        const userSource = audioContext.createMediaStreamSource(userStream);
        userSource.connect(destination);
        
        // We'll add vet audio when they join
        combinedStream = destination.stream;
        
        // Set up MediaRecorder
        mediaRecorder = new MediaRecorder(combinedStream, {
          mimeType: 'audio/webm;codecs=opus'
        });
        
        audioRecordings = [];
        recordingStartTime = Date.now();
        
        mediaRecorder.ondataavailable = (event) => {
          if (event.data.size > 0) {
            audioRecordings.push(event.data);
          }
        };
        
        mediaRecorder.onstop = () => {
          console.log('Call recording stopped');
          processCallRecording();
        };
        
        mediaRecorder.start(1000); // Record in 1-second chunks
        console.log('Call recording started');
        
      } catch (error) {
        console.error('Failed to start call recording:', error);
      }
    }
    
    // Add remote audio to recording
    function addRemoteAudioToRecording(remoteAudioTrack) {
      if (!audioContext || !combinedStream) return;
      
      try {
        // Get the remote audio stream
        const remoteStream = new MediaStream([remoteAudioTrack.getMediaStreamTrack()]);
        const remoteSource = audioContext.createMediaStreamSource(remoteStream);
        
        // Connect to the combined stream destination
        const destination = audioContext.createMediaStreamDestination();
        remoteSource.connect(destination);
        
        console.log('Added remote audio to recording');
      } catch (error) {
        console.error('Failed to add remote audio to recording:', error);
      }
    }
    
    // Stop call recording
    function stopCallRecording() {
      if (mediaRecorder && mediaRecorder.state !== 'inactive') {
        mediaRecorder.stop();
      }
    }
    
    // Process recorded call audio
    async function processCallRecording() {
      if (audioRecordings.length === 0) return;
      
      console.log('Processing call recording...');
      
      try {
        // Combine all recording chunks
        const audioBlob = new Blob(audioRecordings, { type: 'audio/webm;codecs=opus' });
        
        // Store recording data
        const recordingData = {
          audioBlob: audioBlob,
          duration: Date.now() - recordingStartTime,
          timestamp: recordingStartTime,
          size: audioBlob.size
        };
        
        // Save to session storage (will be processed on summary page)
        sessionStorage.setItem('vetai_call_recording', JSON.stringify({
          duration: recordingData.duration,
          timestamp: recordingData.timestamp,
          size: recordingData.size,
          hasAudio: true
        }));
        
        // Convert to base64 for storage
        const reader = new FileReader();
        reader.onload = function() {
          const base64Audio = reader.result.split(',')[1];
          sessionStorage.setItem('vetai_call_audio', base64Audio);
          console.log('Call recording stored successfully');
        };
        reader.readAsDataURL(audioBlob);
        
      } catch (error) {
        console.error('Failed to process call recording:', error);
      }
    }

    // Format duration
    function formatDuration(seconds) {
      const mins = Math.floor(seconds / 60).toString().padStart(2, '0');
      const secs = (seconds % 60).toString().padStart(2, '0');
      return `${mins}:${secs}`;
    }

    // Pet emoji mapping
    function getPetEmoji(petType) {
      const emojis = {
        dog: 'üêï', cat: 'üê±', bird: 'üê¶', rabbit: 'üê∞',
        hamster: 'üêπ', fish: 'üêü', reptile: 'ü¶é', other: 'üêæ'
      };
      return emojis[petType] || 'üêæ';
    }

    // Update status UI
    function updateStatus(status, text) {
      callStatus.className = 'vet-status';
      statusText.textContent = text;
      
      switch (status) {
        case 'waiting':
          callStatus.classList.add('vet-status-connecting');
          callStatus.innerHTML = `<i class="fas fa-circle-notch fa-spin"></i><span>${text}</span>`;
          break;
        case 'connecting':
          callStatus.classList.add('vet-status-connecting');
          callStatus.innerHTML = `<i class="fas fa-circle-notch fa-spin"></i><span>${text}</span>`;
          break;
        case 'active':
          callStatus.classList.add('vet-status-active');
          callStatus.innerHTML = `<i class="fas fa-circle"></i><span>${text}</span>`;
          break;
        case 'ended':
          callStatus.classList.add('vet-status-ended');
          callStatus.innerHTML = `<i class="fas fa-circle"></i><span>${text}</span>`;
          break;
      }
    }

    // Load config and generate token from server
    async function loadConfig() {
      try {
        const res = await fetch('/config');
        const cfg = await res.json();
        appId = cfg.AGORA_APPID;
        
        // Generate a fresh token for this channel and user
        const tokenRes = await fetch(`/api/token?channelName=${channelName}&uid=${USER_UID}&role=publisher`);
        const tokenData = await tokenRes.json();
        token = tokenData.token;
        
        console.log('Got token for channel:', channelName, 'uid:', USER_UID);
        return true;
      } catch (e) {
        console.error('Failed to load config:', e);
        return false;
      }
    }

    function loadBooking() {
      const stored = sessionStorage.getItem('vetai_active_booking') || new URLSearchParams(window.location.search).get('bookingId');
      if (!stored) return null;
      bookingId = stored;
      try {
        const bookings = JSON.parse(localStorage.getItem('vetai_bookings')) || [];
        booking = bookings.find(b => b.id === bookingId) || null;
        return booking;
      } catch (e) {
        return null;
      }
    }

    function updateBookingStatus(newStatus) {
      if (!bookingId) return;
      const bookings = (() => { try { return JSON.parse(localStorage.getItem('vetai_bookings')) || []; } catch (e) { return []; }})();
      const idx = bookings.findIndex(b => b.id === bookingId);
      if (idx >= 0) {
        bookings[idx].status = newStatus;
        localStorage.setItem('vetai_bookings', JSON.stringify(bookings));
      }
    }

    // Load pet info from booking/session
    function loadPetInfo() {
      const booking = loadBooking();
      const stored = sessionStorage.getItem('vetai_pet_info');
      if (booking?.petInfo) {
        petInfo = booking.petInfo;
      } else if (stored) {
        petInfo = JSON.parse(stored);
      }
      if (petInfo) {
        petAvatar.textContent = getPetEmoji(petInfo.petType || petInfo.type);
        petName.textContent = petInfo.petName || petInfo.name || 'Your Pet';
        petDetails.textContent = `${petInfo.petType || petInfo.type || 'Pet'}, ${petInfo.petAge || petInfo.age || ''}`;
      }

      // Display fixed triage summary for Max the dog
      urgencyLevel.textContent = 'Medium';
      recommendationText.textContent = 'Max (5-year-old dog) has not been eating for 3 days and is showing decreased activity levels. This combination of appetite loss and lethargy warrants veterinary evaluation within 24-48 hours to rule out underlying medical conditions and ensure proper nutritional support.';
      return booking;
    }

    // Initialize Agora client
    function initClient() {
      client = AgoraRTC.createClient({ mode: 'rtc', codec: 'vp8' });

      client.on('user-published', async (user, mediaType) => {
        await client.subscribe(user, mediaType);
        console.log('Subscribed to vet:', user.uid, mediaType);

        if (mediaType === 'audio') {
          const remoteAudioTrack = user.audioTrack;
          remoteAudioTrack.play();
          remoteAudioTrack.setVolume(100);
          console.log('Playing vet audio at volume 100');
          audioIndicator.classList.add('speaking');
          audioStatus.textContent = 'Vet is speaking...';
          showToast('Vet audio connected');
          
          // Add vet audio to recording
          addRemoteAudioToRecording(remoteAudioTrack);
        } else if (mediaType === 'video') {
          const playerId = `player-${user.uid}`;
          if (!document.getElementById(playerId)) {
            const wrapper = document.createElement('div');
            wrapper.id = playerId;
            wrapper.className = 'remote-player-wrapper';
            wrapper.innerHTML = `
              <div class="remote-player" id="player-container-${user.uid}"></div>
              <div class="remote-player-name">Veterinarian</div>
            `;
            remotePlayerList.appendChild(wrapper);
          }
          user.videoTrack.play(`player-container-${user.uid}`);
          videoPlaceholder.style.display = 'none';
          videoSection.style.display = 'grid';
        }
      });

      client.on('user-unpublished', (user, mediaType) => {
        if (mediaType === 'audio') {
          audioIndicator.classList.remove('speaking');
          audioStatus.textContent = 'In call with vet';
        } else if (mediaType === 'video') {
          const playerId = `player-${user.uid}`;
          const el = document.getElementById(playerId);
          if (el) el.remove();
          if (!remotePlayerList.querySelector('.remote-player-wrapper')) {
            videoPlaceholder.style.display = 'flex';
          }
        }
      });

      client.on('user-joined', (user) => {
        console.log('Vet joined:', user.uid);
        showToast('Veterinarian connected!');
        
        // Start recording when vet joins
        startCallRecording();
        
        // Update UI for active call
        isInCall = true;
        updateStatus('active', 'In Call');
        audioStatus.textContent = 'Connected with veterinarian';
        audioHint.textContent = 'Speak clearly about your pet\'s condition.';
        callIcon.className = 'fas fa-phone';
        queueInfo.style.display = 'none';
        waitingControls.style.display = 'none';
        controls.style.display = 'flex';
        callDuration.style.display = 'block';
        muteBtn.disabled = false;
        videoBtn.disabled = false;

        // Start duration timer
        callStartTime = Date.now();
        durationInterval = setInterval(() => {
          const elapsed = Math.floor((Date.now() - callStartTime) / 1000);
          callDuration.textContent = formatDuration(elapsed);
        }, 1000);
      });

      client.on('user-left', (user) => {
        console.log('Vet left:', user.uid);
        showToast('Veterinarian has ended the call');
        
        // Stop recording when vet leaves
        stopCallRecording();
        
        updateBookingStatus('awaiting-summary');
        endCall(false);
      });
    }

    // Join channel
    async function joinCall() {
      try {
        updateStatus('connecting', 'Connecting...');
        audioStatus.textContent = 'Connecting to veterinarian...';

        // Join channel with dynamic token
        await client.join(appId, channelName, token, USER_UID);
        console.log('Joined channel:', channelName, 'as UID:', USER_UID);

        // Create and publish audio/video tracks
        const [audioTrack, videoTrack] = await Promise.all([
          AgoraRTC.createMicrophoneAudioTrack(),
          AgoraRTC.createCameraVideoTrack()
        ]);
        localAudioTrack = audioTrack;
        localVideoTrack = videoTrack;

        localVideoTrack.play('local-player', { mirror: true });
        videoSection.style.display = 'grid';
        videoPlaceholder.style.display = 'flex';

        await client.publish([localAudioTrack, localVideoTrack]);
        console.log('Published audio and video tracks');

        showToast('Connected! Waiting for vet...');
      } catch (e) {
        console.error('Failed to join call:', e);
        showToast('Failed to connect. Please try again.');
        updateStatus('ended', 'Connection Failed');
      }
    }

    // Toggle mute
    function toggleMute() {
      if (!localAudioTrack) return;

      isMuted = !isMuted;
      localAudioTrack.setEnabled(!isMuted);

      muteBtn.classList.toggle('muted', isMuted);
      muteBtn.innerHTML = isMuted
        ? '<i class="fas fa-microphone-slash"></i>'
        : '<i class="fas fa-microphone"></i>';

      showToast(isMuted ? 'Muted' : 'Unmuted');
    }

    // Toggle video
    function toggleVideo() {
      if (!localVideoTrack) return;
      isVideoEnabled = !isVideoEnabled;
      localVideoTrack.setEnabled(isVideoEnabled);

      videoBtn.classList.toggle('disabled', !isVideoEnabled);
      videoBtn.innerHTML = isVideoEnabled
        ? '<i class="fas fa-video"></i>'
        : '<i class="fas fa-video-slash"></i>';

      showToast(isVideoEnabled ? 'Camera On' : 'Camera Off');
    }

    // End call
    async function endCall(goToSummary = true) {
      // Stop recording if active
      stopCallRecording();
      
      // Clear intervals
      if (statusPollInterval) clearInterval(statusPollInterval);
      if (durationInterval) clearInterval(durationInterval);

      // Close local tracks
      if (localAudioTrack) {
        localAudioTrack.close();
        localAudioTrack = null;
      }
      if (localVideoTrack) {
        localVideoTrack.stop();
        localVideoTrack.close();
        localVideoTrack = null;
      }

      // Leave channel
      if (client) {
        try {
          await client.leave();
        } catch (e) {}
      }

      if (goToSummary) {
        const bookingId = sessionStorage.getItem('vetai_active_booking');
        if (bookingId) {
          window.location.href = `waiting-room.html?bookingId=${bookingId}`;
          return;
        }
        window.location.href = 'waiting-room.html';
      }
    }

    // Initialize
    async function init() {
      const booking = loadPetInfo();
      if (!booking) {
        window.location.href = 'waiting-room.html';
        return;
      }
      if (booking.status !== 'calling') {
        window.location.href = `waiting-room.html?bookingId=${booking.id}`;
        return;
      }
      channelName = booking.id || sessionStorage.getItem('vetai_call_channel') || localStorage.getItem('vetai_call_channel') || FIXED_CALL_CHANNEL;
      sessionStorage.setItem('vetai_call_channel', channelName);
      localStorage.setItem('vetai_call_channel', channelName);

      // Load config
      const configLoaded = await loadConfig();
      if (!configLoaded) {
        showToast('Configuration error');
        return;
      }

      // Initialize client
      initClient();

      // Join vet-initiated call
      await joinCall();

      // Poll booking status to detect call end by vet
      statusPollInterval = setInterval(() => {
        try {
          const bookings = JSON.parse(localStorage.getItem('vetai_bookings')) || [];
          const b = bookings.find(x => x.id === bookingId);
          if (b && b.status && b.status !== 'calling') {
            window.location.href = `waiting-room.html?bookingId=${bookingId}`;
          }
        } catch (e) {}
      }, 2000);
    }

    // Event listeners
    muteBtn.addEventListener('click', toggleMute);
    videoBtn.addEventListener('click', toggleVideo);
    endBtn.addEventListener('click', () => endCall(true));
    cancelBtn.addEventListener('click', () => endCall(true));

    // Start
    document.addEventListener('DOMContentLoaded', init);
  </script>
</body>
</html>
